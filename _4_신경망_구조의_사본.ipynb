{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_4 신경망 구조의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tigerH/KISS/blob/main/_4_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%EA%B5%AC%EC%A1%B0%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSVzmRVLJrwm"
      },
      "source": [
        "# 신경망 구조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F8W4x9kembv"
      },
      "source": [
        "## 퍼셉트론\n",
        "\n",
        "- 인공신경망의 한 종류\n",
        "- 다수의 입력($x_1, x_2, ..., x_n$)과 가중치($w_1, w_2, ..., w_n$)를 곱하여 그 값에 편향($bias$)을 더한 값이 어느 임계치 값($\\theta$)을 초과하면 활성화 함수를 통과한 출력값을 내보냄\n",
        "![perceptron](https://miro.medium.com/max/1400/1*ofVdu6L3BDbHyt1Ro8w07Q.png)\n",
        "<br /><sub>출처: https://towardsdatascience.com/rosenblatts-perceptron-the-very-first-neural-network-37a3ec09038a</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxALA-qreoJ-"
      },
      "source": [
        "## 뉴런의 수학적 표현\n",
        "\n",
        "![](https://cs231n.github.io/assets/nn1/neuron_model.jpeg)\n",
        "<br /><sub>출처: https://cs231n.github.io/convolutional-networks/</sub>\n",
        "\n",
        "$\\qquad y = f(\\sum_{i} w_ix_i + b) \\quad $\n",
        "\n",
        "  - $f\\ $ : 활성화 함수\n",
        "    - 임계값($\\theta$)을 경계로 출력이 바뀜\n",
        "\n",
        "  - $b\\ \\ $ :  편향\n",
        "    - <u>결정 경계선을 원점에서부터 벗어나게 해줌</u>\n",
        "    - 따로 표현이 없어도 기본적으로 존재한다고 생각\n",
        "\n",
        "  - $\\sum_{i} w_ix_i$ :$\\quad $두 벡터의 내적으로 표현 가능\n",
        "     \n",
        "     $\\\\ \\quad x_1w_1 + x_2w_2 +\\ ... \\ + x_nw_n = w^Tx$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6DMX9Yetsv"
      },
      "source": [
        "\n",
        "## 완전 연결 계층(Fully-Connected Layer) 수학적 표현\n",
        "\n",
        "![](https://miro.medium.com/max/620/1*ZBYO3waYUyPsLm0rb15sEQ.png)\n",
        "<br /><sub>출처: https://towardsdatascience.com/the-sparse-future-of-deep-learning-bce05e8e094a</sub>\n",
        "\n",
        "  $\\qquad  W = [w_0, w_1,\\ ..., \\ w_{M-1}]^T $  \n",
        "  $\\qquad $  각각의 $w_k$는 $N\\times 1$ 형태의 벡터  \n",
        "  $\\qquad W$는 $N \\times M$ 행렬\n",
        "\n",
        "  $ \\qquad b$ = $[b_0, b_1, \\ ..., \\ b_{M-1}]$  \n",
        "\n",
        "  $\\qquad y_0 = f(w_0^Tx + b_0)$  \n",
        "\n",
        "  $\\qquad y_1 = f(w_1^Tx + b_1)$  \n",
        "\n",
        "  $\\qquad y_2 = f(w_2^Tx + b_2)$  \n",
        "  \n",
        "  $\\qquad \\quad ...$\n",
        "\n",
        "  $\\qquad y_{M-1} = f(w_{M-1}^Tx + b_{M-1})$  \n",
        "\n",
        "  $\\quad  \\rightarrow y = f(Wx + b)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH7jWsHRewUi"
      },
      "source": [
        "## 논리회로\n",
        "  * 논리 게이트(Logic Gates)\n",
        "    - AND\n",
        "    - OR\n",
        "    - NOT\n",
        "    - NAND\n",
        "    - NOR  \n",
        "\n",
        "* 다이어그램과 진리표\n",
        "\n",
        "![](http://www.schoolphysics.co.uk/age14-16/Electronics/text/Logic_gates/images/1.png)\n",
        "<br /><sub>출처: http://www.schoolphysics.co.uk/age14-16/Electronics/text/Logic_gates/index.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3pY4J8MezBm"
      },
      "source": [
        "### AND 게이트\n",
        "\n",
        "- 두 입력이 모두 1일 때 1을 출력하는 논리회로   \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/and_logic.jpg)\n",
        "\n",
        "- 진리표\n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/and_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n",
        "\n",
        "- AND 게이트를 만족시키는 가중치와 편향 구하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml6u-oCzenlh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQHe-5E2e2UJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gObrhki8e4hk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDPqdCl1e6fV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gz29P-ve-jD"
      },
      "source": [
        "### OR 게이트\n",
        "\n",
        "- 두 입력 중 하나라도 1이면 1을 출력하는 논리회로  \n",
        "  \n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/or_logic.jpg)\n",
        "\n",
        "- 진리표  \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/or_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n",
        "\n",
        "- OR 게이트를 만족시키는 가중치와 편향 구하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSvmfXve8JR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xc_nF6lfNH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9RrNj4fOez"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3anpbTsfR7A"
      },
      "source": [
        "### NAND 게이트\n",
        "\n",
        "\n",
        "- 두 입력이 모두 1일 때 0을 출력하는 논리회로\n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/nand_logic.jpg)\n",
        "\n",
        "- 진리표  \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/nand_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n",
        "\n",
        "- NAND 게이트를 만족시키는 가중치와 편향 구하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJP5BLDGfP4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juB8y1zIfY7z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6WDqUWefaeX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWVJN3iTfenX"
      },
      "source": [
        "### XOR 게이트\n",
        "\n",
        "- 인공지능 첫번째 겨울\n",
        "- 딥러닝의 첫번째 위기를 초래\n",
        "  - 마빈 민스키와 세이무어 페퍼트에 의해 문제 제기\n",
        "  - AND, NAND와 같은 선형문제는 퍼셉트론으로 해결 가능, 하지만 XOR은 어떻게? 직선(선형) 하나로는 불가능!\n",
        "\n",
        "![](http://ecee.colorado.edu/~ecen4831/lectures/xor2.gif)\n",
        "<br /><sub>출처: http://ecee.colorado.edu/~ecen4831/lectures/NNet3.html</sub>\n",
        "\n",
        "- **다층 퍼셉트론**으로 해결\n",
        "  - 비선형 문제를 해결할 수 있다!\n",
        "\n",
        "- AND, NAND, OR Gate를 조합"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7hNassAfhxK"
      },
      "source": [
        "## 다층 퍼셉트론(Multi Layer Perceptron, MLP)  \n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png)\n",
        "<br /><sub>출처: https://commons.wikimedia.org/wiki/File:MultiLayerNeuralNetworkBigger_english.png</sub>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N6uSU0-L4Oi"
      },
      "source": [
        "### 다층 퍼셉트론의 구성\n",
        "\n",
        "  - 입력층(input layer)\n",
        "  - 은닉층(hidden layer)\n",
        "    - 1개 이상 존재\n",
        "    - 보통 5개 이상 존재하면 Deep Neural Network라고 칭함\n",
        "  - 출력층(output layer)  \n",
        "\n",
        "![](https://www.researchgate.net/profile/Sandip_Lahiri/publication/26614896/figure/fig1/AS:310007494135809@1450922954279/A-schematic-diagram-of-artificial-neural-network-and-architecture-of-the-feed-forward.png)\n",
        "<br /><sub>출처: https://www.researchgate.net/figure/A-schematic-diagram-of-artificial-neural-network-and-architecture-of-the-feed-forward_fig1_26614896</sub>\n",
        "\n",
        "  - 수식 \n",
        "\n",
        "    - (input layer $\\rightarrow$ hidden layer)   \n",
        "  $ \\quad z = f_L(W_Lx + b_L) $  \n",
        "\n",
        "    - (hidden layer $\\rightarrow$ output layer)   \n",
        "  $ \\quad y = a_K(W_Kz + b_K) $  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38mOWdHzfsO_"
      },
      "source": [
        "### XOR 게이트\n",
        "- 서로 다른 두 값이 입력으로 들어가면 1을 반환\n",
        "\n",
        "- 진리표  \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/xor_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VULVZbxVfb_M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFcXlWJKfuLg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgdNIo5dfx2Y"
      },
      "source": [
        "## 활성화 함수(Activation Function)\n",
        "\n",
        "- 입력 신호의 총합을 출력 신호로 변환하는 함수\n",
        "- 활성화 함수에 따라 출력값이 결정\n",
        "- 단층, 다층 퍼셉트론 모두 사용\n",
        "- 대표적인 활성화 함수\n",
        "  - Sigmoid\n",
        "  - ReLU\n",
        "  - tanh \n",
        "  - Identity Function\n",
        "  - Softmax\n",
        "\n",
        "-  하나의 layer에서 다음 layer로 넘어갈 때는 항상 활성화 함수를 통과\n",
        "    \n",
        "- [참고] 여러가지 활성화 함수  \n",
        " https://en.wikipedia.org/wiki/Activation_function  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqLlBrSEf31I"
      },
      "source": [
        "### Step Function(계단 함수)\n",
        "\n",
        "### $\\quad y = \\begin{cases}\n",
        "0 \\quad (x < 0) \\\\\n",
        "1 \\quad (x \\ge 0)\n",
        "\\end{cases} $   \n",
        "\n",
        "![](https://www.intmath.com/laplace-transformation/svg/svgphp-unit-step-functions-definition-1a-s1.svg)\n",
        "<br /><sub>출처: https://www.intmath.com/laplace-transformation/1a-unit-step-functions-definition.php</sub>\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQS9fxpfIZLS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9wJ-Ht1fvpi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYjdSmUf5zm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OKFVCMqf9uc"
      },
      "source": [
        "\n",
        "### Sigmoid Function(시그모이드 함수)\n",
        "- 이진분류(binary classification)에 주로 사용\n",
        "  - 마지막 출력층의 활성화 함수로 사용\n",
        "- 출력값이 0~1 의 값이며, 이는 **확률**로 표현 가능\n",
        "\n",
        "\n",
        "$\\quad y = \\frac{1}{1 + e^{-x}}$\n",
        "\n",
        "![](https://media.geeksforgeeks.org/wp-content/uploads/20190911181329/Screenshot-2019-09-11-18.05.46.png)\n",
        "<br /><sub>출처: https://www.geeksforgeeks.org/implement-sigmoid-function-using-numpy/</sub>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q7Ywp-Pf7gC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZcSKcAYgB9d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1x6bb83gFWv"
      },
      "source": [
        "### 시그모이드 함수와 계단 함수 비교\n",
        "\n",
        "- 공통점\n",
        "  - 출력값이 0~1 내의 범위\n",
        "  - 입력값의 정도에 따라 출력값의 정도가 달라짐 \n",
        "    즉, 입력이 중요하면(입력값이 크면) 큰 값을 출력\n",
        "    \n",
        "- 차이점  \n",
        " 계단함수에 비해 시그모이드 함수는 \n",
        "  - 입력에 따라 출력이 연속적으로 변화\n",
        "  - 출력이 '매끄러움'  \n",
        "    이는 모든 점에서 **미분 가능**함을 의미\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67UOGQfJgDg8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q3FQagJgJDs"
      },
      "source": [
        "\n",
        "### ReLU(Rectified Linear Unit)\n",
        "\n",
        "- 가장 많이 쓰이는 함수 중 하나  \n",
        "  \n",
        "  ### $ y = \\begin{cases}\n",
        "0 \\quad (x \\le 0) \\\\\n",
        "x \\quad (x > 0)\n",
        "\\end{cases} $\n",
        "\n",
        "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png)\n",
        "<br /><sub>출처: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/</sub>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cEsh_FqgHUr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYbYYssSgLyP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWXjAqjngPi0"
      },
      "source": [
        "\n",
        "### 하이퍼볼릭탄젠트 함수(Hyperbolic tangent function, tanh)\n",
        "\n",
        " ### $ \\quad y = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
        "\n",
        "![](https://ww.namu.la/s/aeff20070260dc095f50d1ec74f1d4dd96bab65016ab1b01bed2145850e165e7c713734ff60047392c522e784bec9605782e4cacb2606725d782714917e2a47456d4c4a308c4b4bcc7f9a905b357556b912b404573385c42ba30e41a627dd31a)\n",
        "<br /><sub>출처: https://namu.wiki/w/%EC%8C%8D%EA%B3%A1%EC%84%A0%20%ED%95%A8%EC%88%98</sub>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF3lGXSegNZJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6GCAu1DgSAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2bVEk3GgVDL"
      },
      "source": [
        "### Identity Function(항등 함수)\n",
        "- 회귀(Regression) 문제에서 주로 사용  \n",
        "  - 출력층의 활성화 함수로 활용\n",
        "\n",
        "- $y=x$\n",
        "\n",
        "- 입력값 그대로 출력하기 때문에 굳이 정의할 필요는 없지만  \n",
        "  신경망 중간 레이어 흐름과 통일하기 위해 사용\n",
        "\n",
        "![](https://math.info/image/394/identity_function.jpg)\n",
        "<br /><sub>출처: https://math.info/Algebra/Identity_Function/</sub>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC3M0oq_gTgY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V50HKDVMgXgh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npL99RRugad-"
      },
      "source": [
        "### Softmax\n",
        "\n",
        "- 다중 클래스 분류에 사용(Multi Class Classification)\n",
        "- 입력값의 영향을 크게 받음  \n",
        "  입력값이 크면 출력값도 큼\n",
        "- 출력값을 확률에 대응가능\n",
        "- 출력값의 **총합은 1**\n",
        "\n",
        "- 수식  \n",
        " ### $ y_k = \\frac{exp(a_k)}{\\sum_{i=1}{exp(a_i)}}$\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*670CdxchunD-yAuUWdI7Bw.png)\n",
        "<br /><sub>출처: https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d</sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ku0ucpygYrE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HikF6Peigdew"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYIgC71lghbo"
      },
      "source": [
        "#### 소프트맥스 함수 주의점\n",
        "- 오버플로우(overflow) 문제\n",
        "- 지수함수(exponential function)을 사용하기 때문에  \n",
        "  입력값이 너무 크면 무한대(inf)가 반환됨\n",
        "\n",
        "- 개선한 수식\n",
        " ## $y_k = \\frac{exp(a_k)}{\\sum_{i=1}{exp(a_i)}} = \\frac{Cexp(a_k)}{C\\sum_{i=1}{exp(a_i)}} \\\\\n",
        "  \\quad = \\frac{exp(a_k + logC)}{\\sum_{i=1}{exp(a_i + logC)}} \\\\\n",
        "  \\quad = \\frac{exp(a_k + C')}{\\sum_{i=1}{exp(a_i + C')}}\n",
        "  $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmuXmRY8gfWc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJADjg8Zgjab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQTWqn2fgk42"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1cWHyPbgoaH"
      },
      "source": [
        "### 활성화 함수를 비선형 함수(non-linear function)로 사용하는 이유\n",
        "- 신경망을 깊게(deep) 하기 위함\n",
        "- 만약 활성화 함수를 선형함수(linear function)으로 하게 되면 은닉층의 갯수가 여러개이더라도 의미가 없어짐\n",
        "- 만약,$\\ h(x) = cx이고, 3개의 은닉층이 존재한다면 \n",
        "\\\\  \n",
        "y = h(h(h(x)))  \\\\\n",
        "\\ \\ = c*c*c*x \\\\\n",
        "\\ \\ = c^3x \\\\ $  \n",
        "이므로 결국에는 선형함수가 되어버림\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD3C4UcVgrxk"
      },
      "source": [
        "### 그 외의 활성화 함수\n",
        "- LeakyReLU\n",
        "\n",
        "### $ \\ \\ f_a(x) = \\begin{cases}\n",
        "x \\quad (x \\ge 0) \\\\\n",
        "ax \\quad (x < 0)\n",
        "\\end{cases}$ \n",
        "\n",
        "![](https://i0.wp.com/knowhowspot.com/wp-content/uploads/2019/04/IMG_20190406_220045-1.jpg)\n",
        "<br /><sub>출처: https://knowhowspot.com/technology/ai-and-machine-learning/artificial-neural-network-activation-function/</sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BigOia-QgmcF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY2YbDJ0g1Aw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDh7qyImg4me"
      },
      "source": [
        "- ELU(Exponential Linear Units)  \n",
        "\n",
        "  $ f(\\alpha, x) = \\begin{cases}\n",
        "\\alpha \\ (e^x - 1) \\quad (x \\le 0) \\\\\n",
        "x \\qquad \\qquad (x > 0)\n",
        "\\end{cases}$  \n",
        "\n",
        "![](https://www.researchgate.net/publication/331794632/figure/fig1/AS:736888264609792@1552699261431/Exponential-Linear-Unit-activation-function-input-output-mapping-The-activation-function.jpg)\n",
        "<br /><sub>출처: https://www.researchgate.net/figure/Exponential-Linear-Unit-activation-function-input-output-mapping-The-activation-function_fig1_331794632</sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nImmUf9g2lV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kZVCKTxg_RX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir3K7hhLhCf2"
      },
      "source": [
        "### 활성화 함수 참고\n",
        "\n",
        "- 일반적인 사용 순서\n",
        "  1. ELU\n",
        "  2. LeakyReLU\n",
        "  3. ReLU\n",
        "  4. tanh \n",
        "  5. sigmoid 순으로 사용\n",
        "\n",
        "- 스탠포드 강의에서 언급한 사용 순서\n",
        "  1. ReLU\n",
        "  2. ReLU Family(LeakyReLU, ELU)\n",
        "  3. sigmoid는 사용 X  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT27FzpXhJTF"
      },
      "source": [
        "## 3층 신경망 구현하기\n",
        "\n",
        "![](http://ufldl.stanford.edu/tutorial/images/Network3322.png)\n",
        "<br /><sub>출처: http://deeplearning.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/</sub>\n",
        "\n",
        "\n",
        "- 2클래스 분류\n",
        "- 입력층(Input Layer)\n",
        "  - 뉴런수: 3\n",
        "\n",
        "- 은닉층(Hidden Layers)\n",
        "  - 첫번째 은닉층\n",
        "    - 뉴런수: 3\n",
        "  - 두번째 은닉층\n",
        "    - 뉴런수: 2\n",
        "- 출력층(Output Layer)\n",
        "  - 뉴런수: 2  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2uxTBC3hQVh"
      },
      "source": [
        "### 활성화 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEkt97EhPux"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgjFPw3DhUbO"
      },
      "source": [
        "### 레이어 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNygpfXRhS4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gW4luZ3hVqk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7cgikzahYYj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhGH6HgvhZ7r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpTPdvrbhbja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd2lyMzhwf7Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_oQoRFYhf-4"
      },
      "source": [
        "### 신경망 추론 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFwxQXrShc-1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}